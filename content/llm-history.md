---
title: Generative AI History
---

### The Timeline

> [!abstract] 2017: Attention Is All You Need
> **The Spark:** Google Brain team proposed the Transformer architecture.
> **Key Insight:** RNNs are slow; Self-attention is parallelizable.
>
> ⬇️ **Led to:** BERT (2018), GPT-1 (2018)

> [!info] 2020: GPT-3
> **The Scale:** 175B parameters. Few-shot learning emerging.
> **Impact:** AI 开始展现出通用的文本生成能力。

test